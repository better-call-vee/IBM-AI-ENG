> [!info] Overfitting and the Final Exam Analogy
> **Overfitting:** Happens when a model trained on too little data learns **superficial tricks** that work only for the training set, not the real underlying pattern.  
> 
> When tested on **new, unseen data**, it performs poorly because its "knowledge" is shallow.
> 
> **Why we split data:**  
> - **Training Set (80%)** → Model studies pages 1–80 of a 100-page textbook, reviewing as much as needed to learn patterns.  
> - **Testing Set (20%)** → Final exam with questions from unseen pages 81–100.  
> 
> **Purpose:**  
> - If the model learned **general patterns**, it will perform well on the test set.  
> - If it only **memorized answers**, it will fail the final exam.  
> - This test checks if the model can **generalize** its knowledge to truly unseen situations.
>
